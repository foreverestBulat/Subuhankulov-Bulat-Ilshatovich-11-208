# SUBUHANKULOV BULAT 11-208
Основы информационного поиска

## Зависимости
Проверьте, что у вас есть python:
`python --version` или `python3 --version`
Создайте окружение:
```
python -m venv venv
```
Установите зависимости:
```
pip install -r requirements.txt
```
## [Задание-1] Запустите краулер (сразу начнется скачиваться страницы из википедии):
```
python task.py crawl -od pages -if index.txt
```
Дождитесь окончания скачивания 100 страниц в терминале. В корне проекта появится папка `pages` и файл `index.txt` (заполнится после завершения).

## [Задание-2] Создание токенов и лемм
```
python task.py nlp -id pages -od data
```
После того как `pages` заполнится можете вызвать эту команду. \
Результат: появится папка `data` внутри который для каждой страницы есть файл лемм и токенов.

## [Задание-3] Инвертированный индекс и поиск
```
python task.py index -id pages -of inverted_index.json
```
После того как `pages` заполнится можете вызвать эту команду. \
Результат: появится файл `inverted_index.json` внутри которого каждому слову написано, странице есть это слово. После в терминале будет поиск

## [Задание-4] Вычисление TF-IDF
```
python task.py tfidf -id pages -ot tf_idf_tokens -ol tf_idf_lemmas
```
После того как `pages` заполнится можете вызвать эту команду. \
Результат: появится две папки `tf_idf_lemmas` и `tf_idf_tokens` в которых содержится для каждого токена и леммы для каждой страницы TF и IDF

## [Задание-5] Векторный поиск
```
python task.py search -td tf_idf_lemmas -if index.txt
```
После того как закончится вычисление TF-IDF можете вызвать эту команду. \
Результат: в терминале можно вводить слова, в результате покажет на каких страницах есть это слово


